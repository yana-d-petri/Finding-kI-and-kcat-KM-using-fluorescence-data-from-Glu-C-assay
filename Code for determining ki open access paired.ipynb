{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ab6c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import scipy\n",
    "from scipy.optimize import curve_fit\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + '/usr/local/texlive/2021/bin/x86_64-linux'\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb1d5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('bmh')\n",
    "plt.rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6356aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family':'serif','size':30, 'serif': ['computer modern roman']}\n",
    "plt.rc('font',**font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d993e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "plt.rc('axes', grid=False, facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e85f8a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will beging by loading raw florescent data for this experiment into Python \n",
    "data_rep1 = pandas.read_excel('Raw fluorescence vs time using 4 uM PLE 1 uM Glu-C and 10 uM Opt-3 rep 1.xlsx',engine='openpyxl')\n",
    "data_rep2 = pandas.read_excel('Raw fluorescence vs time using 4 uM PLE 1 uM Glu-C and 10 uM Opt-3 rep 2.xlsx',engine='openpyxl')\n",
    "\n",
    "#Reading in the columns\n",
    "data_rep1_column = data_rep1.columns\n",
    "data_rep2_column = data_rep2.columns\n",
    "\n",
    "#Importing times corresponding to fluorescence data points\n",
    "T_rep1 = (data_rep1[data_rep1_column[1]].values)[1:]\n",
    "T_rep1 = np.array(T_rep1,dtype='float64')\n",
    "\n",
    "T_rep2 = (data_rep2[data_rep2_column[1]].values)[1:]\n",
    "T_rep2 = np.array(T_rep2,dtype='float64')\n",
    "\n",
    "#Importing background fluorescence values of the buffer \n",
    "buffer_rep1 = (data_rep1[data_rep1_column[-3:]].values)[1:].T\n",
    "buffer_rep2 = (data_rep2[data_rep2_column[-3:]].values)[1:].T\n",
    "\n",
    "#Defining an array with dimensions  3 x T_rep where the first dimension is 3 replicates and\n",
    "#the third is fluorescent values taken every 20 seconds\n",
    "F_PG_rep1 = np.zeros((3,len(T_rep1)))\n",
    "F_PG_rep2 = np.zeros((3,len(T_rep2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9873fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"PG\" corresponds to esterified substrate + PLE + Glu-C, \"P\" to substrate + PLE, and \"G\" to substrate + Glu-C\n",
    "#\"Fmax\" corresponds to fluorescence of Opt + Glu-C\n",
    "#Filling the array with data\n",
    "for a in range(3):\n",
    "        F_PG_rep1[a,:] = (data_rep1[data_rep1_column[2+a]].values)[1:] - buffer_rep1[a,:]\n",
    "        F_PG_rep2[a,:] = (data_rep2[data_rep2_column[2+a]].values)[1:] - buffer_rep2[a,:]\n",
    "\n",
    "F_P_rep1 = np.zeros((3,len(T_rep1)))\n",
    "F_P_rep2 = np.zeros((3,len(T_rep2)))\n",
    "\n",
    "for a in range(3):\n",
    "        F_P_rep1[a,:] = (data_rep1[data_rep1_column[5+a]].values)[1:] - buffer_rep1[a,:]\n",
    "        F_P_rep2[a,:] = (data_rep2[data_rep2_column[5+a]].values)[1:] - buffer_rep2[a,:]\n",
    "              \n",
    "F_G_rep1 = np.zeros((3,len(T_rep1)))\n",
    "F_G_rep2 = np.zeros((3,len(T_rep2)))\n",
    "   \n",
    "for a in range(3):\n",
    "        F_G_rep1[a,:] = (data_rep1[data_rep1_column[8+a]].values)[1:] - buffer_rep1[a,:]\n",
    "        F_G_rep2[a,:] = (data_rep2[data_rep2_column[8+a]].values)[1:] - buffer_rep2[a,:]\n",
    "        \n",
    "F_max_rep1 = np.zeros((3,len(T_rep1)))\n",
    "F_max_rep2 = np.zeros((3,len(T_rep2)))\n",
    "\n",
    "for a in range(3):\n",
    "        F_max_rep1[a,:] = (data_rep1[data_rep1_column[11+a]].values)[1:] - buffer_rep1[a,:]\n",
    "        F_max_rep2[a,:] = (data_rep2[data_rep2_column[11+a]].values)[1:] - buffer_rep2[a,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29c6eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking the average of times across 2 datasets      \n",
    "T = (T_rep1 + T_rep2)/2 #assume no error here\n",
    "T = T + 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f99cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding average F_PG, F_P, F_G, and F_max for plotting along with corresopnding SD\n",
    "\n",
    "F_PG_compile = np.concatenate((F_PG_rep1,F_PG_rep2),axis=0)\n",
    "F_PG_averaged = np.mean(F_PG_compile,axis=0)\n",
    "std_F_PG_rep1 = np.std(F_PG_rep1, axis=0)\n",
    "std_F_PG_rep2 = np.std(F_PG_rep2, axis=0)\n",
    "F_PG_std = np.sqrt((std_F_PG_rep1**2 + std_F_PG_rep2**2)/4)\n",
    "\n",
    "F_P_compile = np.concatenate((F_P_rep1,F_P_rep2),axis=0)\n",
    "F_P_averaged = np.mean(F_P_compile,axis=0)\n",
    "std_F_P_rep1 = np.std(F_P_rep1, axis=0)\n",
    "std_F_P_rep2 = np.std(F_P_rep2, axis=0)\n",
    "F_P_std = np.sqrt((std_F_P_rep1**2 + std_F_P_rep2**2)/4)\n",
    "\n",
    "F_G_compile = np.concatenate((F_G_rep1,F_G_rep2),axis=0)\n",
    "F_G_averaged = np.mean(F_G_compile,axis=0)\n",
    "std_F_G_rep1 = np.std(F_G_rep1, axis=0)\n",
    "std_F_G_rep2 = np.std(F_G_rep2, axis=0)\n",
    "F_G_std = np.sqrt((std_F_G_rep1**2 + std_F_G_rep2**2)/4)\n",
    "\n",
    "F_max_compile = np.concatenate((F_max_rep1,F_max_rep2),axis=0)\n",
    "F_max_averaged = np.mean(F_max_compile,axis=0)\n",
    "std_F_max_rep1 = np.std(F_max_rep1, axis=0)\n",
    "std_F_max_rep2 = np.std(F_max_rep2, axis=0)\n",
    "F_max_std = np.sqrt((std_F_max_rep1**2 + std_F_max_rep2**2)/4)\n",
    "\n",
    "#Exporting average F_PG, F_P, F_G, and F_max for plotting along with corresopnding SD and time into Excel for plotting \n",
    "F_PG_averaged_df = pandas.DataFrame(F_PG_averaged)\n",
    "F_P_averaged_df = pandas.DataFrame(F_P_averaged)\n",
    "F_G_averaged_df = pandas.DataFrame(F_G_averaged)\n",
    "F_max_averaged_df = pandas.DataFrame(F_max_averaged)\n",
    "T_df = pandas.DataFrame(T)\n",
    "\n",
    "F_PG_std_df = pandas.DataFrame(F_PG_std)\n",
    "F_P_std_df = pandas.DataFrame(F_P_std)\n",
    "F_G_std_df = pandas.DataFrame(F_G_std)\n",
    "F_max_std_df = pandas.DataFrame(F_max_std)\n",
    "\n",
    "with pandas.ExcelWriter('OUTPUT_ki_Opt-3_Fluorescence_Averaged_Progress_Curves.xlsx', engine='openpyxl') as writer:\n",
    "    \n",
    "    F_PG_averaged_df.to_excel(writer, sheet_name='F_PG_av')\n",
    "    F_P_averaged_df.to_excel(writer, sheet_name='F_P_av')\n",
    "    F_G_averaged_df.to_excel(writer, sheet_name='F_G_av')\n",
    "    F_max_averaged_df.to_excel(writer, sheet_name='F_max_av')\n",
    "    T_df.to_excel(writer, sheet_name='T')\n",
    "\n",
    "    F_PG_std_df.to_excel(writer, sheet_name='F_PG_std')\n",
    "    F_P_std_df.to_excel(writer, sheet_name='F_P_std')\n",
    "    F_G_std_df.to_excel(writer, sheet_name='F_G_std')\n",
    "    F_max_std_df.to_excel(writer, sheet_name='F_max_std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "214ef765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining substrate concentration used in the experiment\n",
    "Sub_conc = [10]\n",
    "\n",
    "#Randomly pairing F_PG, F_G, F_max, and F_P from either from rep1 (and then doing the same thing with rep2)\n",
    "Pt_rep1 = np.zeros((3**4,len(T)))\n",
    "Pt_rep2 = np.zeros((3**4,len(T)))\n",
    " \n",
    "import itertools\n",
    "index = 0\n",
    "for a,b,c,d in itertools.product(range(3),repeat=4):\n",
    "    Pt_rep1[index,:] = Sub_conc[0]*(F_PG_rep1[a]-F_G_rep1[b])/(F_max_rep1[c]-F_P_rep1[d])\n",
    "    Pt_rep2[index,:] = Sub_conc[0]*(F_PG_rep2[a]-F_G_rep2[b])/(F_max_rep2[c]-F_P_rep2[d])\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d20fe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_min [s] = 150\n",
      "t_max [s] = 1500\n"
     ]
    }
   ],
   "source": [
    "#Finding standard deviation of all product concentrations that resulted from random pairings\n",
    "#Also doing the same for rep1\n",
    "std_Pt_rep1 = np.std(Pt_rep1, axis=0)\n",
    "std_Pt_rep2 = np.std(Pt_rep2, axis=0)\n",
    "\n",
    "#Propagating error for finding standard deviation in the two replicates \n",
    "Pt_std = np.sqrt((std_Pt_rep1**2 + std_Pt_rep2**2)/4)\n",
    "    \n",
    "Pt = np.concatenate((Pt_rep1,Pt_rep2),axis=0)\n",
    "\n",
    "#finding the average of all product concentrations that resulted from random pairings\n",
    "Pt_averaged = np.mean(Pt,axis=0)\n",
    "\n",
    "'''\n",
    "#Remove commenting out for plotting\n",
    "#The part below is a visual check (plotting [P]t +/- STD vs time)\n",
    "plt.plot(T,Pt_averaged,'k-',linewidth=2.5)\n",
    "plt.plot(T,Pt_averaged+Pt_std,'k-',linewidth=1,alpha=0.3,label='STD')\n",
    "plt.plot(T,Pt_averaged-Pt_std,'k-',linewidth=1,alpha=0.3)#,label='_nolegend_')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('[P]t (uM)')\n",
    "plt.title('[P]t with STD error vs time')\n",
    "plt.legend(fontsize='x-small')\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "#import sys\n",
    "#sys.exit(0)\n",
    "\n",
    "#Defining the windown of time in which kI will be fit\n",
    "tmin = 150 #other tested times: #200 #300 #150 #1 #100 #150\n",
    "tmax = 1500 #other tested times: #2000 #1500 #2000 #1500 #1000 #2500 #2100\n",
    "\n",
    "# window of time that will be used for the fit\n",
    "window = (T>tmin)*(T<tmax)\n",
    "\n",
    "#Note that we checked that the obtained kI is not strongly sensitive to the chosen tmin-tmax range\n",
    "print(\"t_min [s] =\", tmin)\n",
    "print(\"t_max [s] =\", tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59321055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted k_I [1/s] = 0.003185705691107232\n",
      "fitted half-life [min] = 3.6263403243999046\n",
      "fitted P_inf [uM] = 9.108365926719447\n",
      "fitted I_tmin [uM] = 6.934285741105716\n",
      "95% confidence interval on fitted k_I [1/s] = 0.00011929097415892233\n",
      "STD on fitted k_I [1/s] = 6.086274191781751e-05\n",
      "95% confidence interval on fitted P_inf[uM] = 0.08708998971446187\n",
      "95% confidence interval on fitted half-life [min] = 0.1357908456945673\n",
      "95% confidence interval on fitted I_tmin [uM] = 0.08962607114969501\n",
      "time [s] in the chosen window = [ 155.0715  175.081   195.0895  215.0975  235.1075  255.1175  275.1255\n",
      "  295.135   315.144   335.1545  355.1635  375.1735  395.1825  415.1915\n",
      "  435.2035  455.213   475.2215  495.236   515.2455  535.262   555.2705\n",
      "  575.284   595.2935  615.302   635.3105  655.323   675.337   695.3465\n",
      "  715.3625  735.3715  755.3815  775.3945  795.404   815.4155  835.424\n",
      "  855.432   875.4445  895.4535  915.4665  935.476   955.489   975.498\n",
      "  995.5065 1015.5275 1035.5365 1055.5475 1075.5585 1095.5695 1115.578\n",
      " 1135.586  1155.595  1175.604  1195.6125 1215.624  1235.636  1255.645\n",
      " 1275.6545 1295.6735 1315.689  1335.6975 1355.706  1375.7155 1395.724\n",
      " 1415.7325 1435.742  1455.7505 1475.7595 1495.783 ]\n",
      "fitted [P]t [uM] = [2.28521247 2.70657764 3.10190219 3.4728056  3.82083915 4.1473793\n",
      " 4.45372376 4.74117209 5.01086247 5.26391685 5.5013258  5.72408466\n",
      " 5.93307655 6.12916242 6.31316598 6.4857841  6.64773431 6.79972787\n",
      " 6.94229826 7.07610951 7.20160583 7.31938097 7.42986008 7.53351152\n",
      " 7.63076226 7.72202521 7.8076576  7.88798309 7.96337178 8.03407941\n",
      " 8.10042379 8.16268    8.22108102 8.27588077 8.32728857 8.37552065\n",
      " 8.42078422 8.46324494 8.50309126 8.54047012 8.57554657 8.60845014\n",
      " 8.63932104 8.66830312 8.69547863 8.72097842 8.74490334 8.76735068\n",
      " 8.78840912 8.80816668 8.8267051  8.84409869 8.86041778 8.87573135\n",
      " 8.89009948 8.90357824 8.91622494 8.9280961  8.93923193 8.94967633\n",
      " 8.95947576 8.96867051 8.97729701 8.9853908  8.99298515 9.00011017\n",
      " 9.00679536 9.01307212]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nplt.plot(T,Pt_averaged,'k-',linewidth=2.5)\\nplt.plot(T,Pt_averaged+Pt_std,'k--',linewidth=1,alpha=0.3,label='STD')\\nplt.plot(T,Pt_averaged-Pt_std,'k--',linewidth=1,alpha=0.3)#,label='_nolegend_')\\nplt.plot(T[window],func(T[window],Pinf,Itmin,kI),'r--',linewidth=3, label='Exponential fit')\\nplt.xlabel('Time (s)')\\nplt.ylabel('[P]t (uM)')\\nplt.title('[P]t with STD error vs time')\\nplt.legend(fontsize='x-small')\\nplt.axvline(x=tmin,linestyle='-',color='black',alpha=0.3,label='_nolegend_')\\nplt.axvline(x=tmax,linestyle='-',color='black',alpha=0.3,label='_nolegend_')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Definining the formula [P]t = [P]inf - [I]tmin*e^(-ki*(t-tmin)) with three free fitting parameters\n",
    "def func(t,Pinf,Itmin,kI): return Pinf - Itmin*np.exp(-kI*(t-tmin)) \n",
    "\n",
    "#Fitting the three independent parameters using curve_fit\n",
    "#p0=[10,10,0.01] are the initial guesses as to what Pinf,Itmin, and kI are 10 uM, 10 uM, and 0.01 s-1, respectively\n",
    "parameters = curve_fit(func,T[window],Pt_averaged[window],p0=[10,10,0.01],sigma=Pt_std[window],absolute_sigma=True)\n",
    "Pinf,Itmin,kI = parameters[0]\n",
    "\n",
    "#parameters[1] contains the covariance matrix; square root of the diagonal values are standard deviations\n",
    "Pinf_SD,Itmin_SD,kI_SD = np.sqrt(np.diag(parameters[1]))\n",
    "\n",
    "#half-life of the quinone methide intermediate\n",
    "t_half = np.log(2)/kI*(1/60)\n",
    "\n",
    "#Standard deviation error on the half-life\n",
    "t_half_SD = (t_half*kI_SD)/kI\n",
    "\n",
    "#95% confidence intervals on the errors\n",
    "t_half_95_conf_int = t_half_SD*1.96\n",
    "kI_95_conf_int = kI_SD*1.96\n",
    "Pinf_95_conf_int = Pinf_SD*1.96\n",
    "Itmin_conf_int = Itmin_SD*1.96\n",
    "\n",
    "print(\"fitted k_I [1/s] =\", kI)\n",
    "print(\"fitted half-life [min] =\", t_half)\n",
    "print(\"fitted P_inf [uM] =\", Pinf)\n",
    "print(\"fitted I_tmin [uM] =\", Itmin)\n",
    "\n",
    "print(\"95% confidence interval on fitted k_I [1/s] =\", kI_95_conf_int)\n",
    "print(\"STD on fitted k_I [1/s] =\", kI_SD)\n",
    "print(\"95% confidence interval on fitted P_inf[uM] =\", Pinf_95_conf_int)\n",
    "print(\"95% confidence interval on fitted half-life [min] =\", t_half_95_conf_int)\n",
    "print(\"95% confidence interval on fitted I_tmin [uM] =\", Itmin_conf_int)\n",
    "\n",
    "print(\"time [s] in the chosen window =\", T[window])\n",
    "print(\"fitted [P]t [uM] =\", func(T[window],Pinf,Itmin,kI))\n",
    "\n",
    "'''\n",
    "plt.plot(T,Pt_averaged,'k-',linewidth=2.5)\n",
    "plt.plot(T,Pt_averaged+Pt_std,'k--',linewidth=1,alpha=0.3,label='STD')\n",
    "plt.plot(T,Pt_averaged-Pt_std,'k--',linewidth=1,alpha=0.3)#,label='_nolegend_')\n",
    "plt.plot(T[window],func(T[window],Pinf,Itmin,kI),'r--',linewidth=3, label='Exponential fit')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('[P]t (uM)')\n",
    "plt.title('[P]t with STD error vs time')\n",
    "plt.legend(fontsize='x-small')\n",
    "plt.axvline(x=tmin,linestyle='-',color='black',alpha=0.3,label='_nolegend_')\n",
    "plt.axvline(x=tmax,linestyle='-',color='black',alpha=0.3,label='_nolegend_')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "021591c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Remove commenting out for plotting\\n#The part below is a visual check(plotting [I]t with error vs time)\\nplt.plot(T_der,dPdt_averaged,'k-',linewidth=2.5)\\nplt.plot(T_der,dPdt_averaged+dPdt_std,'k-',linewidth=1,alpha=0.3,label='STD')\\nplt.plot(T_der,dPdt_averaged-dPdt_std,'k-',linewidth=1,alpha=0.3)#,label='_nolegend_')\\nplt.xlabel('Time (s)')\\nplt.ylabel('dPdt (uM s-1)')\\nplt.title('dPdt with STD error vs time')\\nplt.legend(fontsize='x-small')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now, knowing kI, we can also plot [I]t vs t and [I]t + [P]t vs t\n",
    "#The formula for [I]t is I = dPdt/kI\n",
    "#We first find dPdt\n",
    "\n",
    "#In the manuscript, n = nr + nl\n",
    "n = 4 #Spacing of n between subsequent concentrations was chosen to compute the derivative dPdt\n",
    "#Note that the value of dPdt is not very sensitive to the choice of n\n",
    "\n",
    "#dPdt = ki*[I]t\n",
    "#The function above is easy to plot, but error propagation on dPdt from error on Pt_averaged is challenging\n",
    "#To avoid challenging math/overestimating the error, we will take an alternative appriach:\n",
    "#For each of the 6 replicates (3 technical, 2 indepednent), dPdt will be found (6 values per concentration)\n",
    "#Then, the regular error propagation formula will be applied to the 6 resultant values of dPdt \n",
    "\n",
    "#Finding derivative curves for 81 Pt curves in each of the rep (rep 1 and rep 2)\n",
    "dPdt_rep1 = (Pt_rep1[:,n:] - Pt_rep1[:,:-n])/(T[n:] - T[:-n]) #Computing dPdt for 81 Pt curves in rep1 \n",
    "dPdt_rep2 = (Pt_rep2[:,n:] - Pt_rep2[:,:-n])/(T[n:] - T[:-n]) #Computing dPdt for 81 Pt curves in rep2\n",
    "\n",
    "#Finding standard deviations corresponding to the derivative curves\n",
    "std_dPdt_rep1 = np.std(dPdt_rep1, axis=0)\n",
    "std_dPdt_rep2 = np.std(dPdt_rep2, axis=0)\n",
    "\n",
    "#Propagating error for finding standard deviation in the two replicates \n",
    "dPdt_std = np.sqrt((std_dPdt_rep1**2 + std_dPdt_rep2**2)/4)\n",
    "dPdt = np.concatenate((dPdt_rep1,dPdt_rep2),axis=0)\n",
    "\n",
    "#Dinding the average of all derivative curves that resulted from product curves\n",
    "dPdt_averaged = np.mean(dPdt,axis=0)\n",
    "\n",
    "T_der = (T[n:] + T[:-n])/2 #Computing times corresponding to derivative dPdt\n",
    "\n",
    "'''\n",
    "#Remove commenting out for plotting\n",
    "#The part below is a visual check(plotting [I]t with error vs time)\n",
    "plt.plot(T_der,dPdt_averaged,'k-',linewidth=2.5)\n",
    "plt.plot(T_der,dPdt_averaged+dPdt_std,'k-',linewidth=1,alpha=0.3,label='STD')\n",
    "plt.plot(T_der,dPdt_averaged-dPdt_std,'k-',linewidth=1,alpha=0.3)#,label='_nolegend_')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('dPdt (uM s-1)')\n",
    "plt.title('dPdt with STD error vs time')\n",
    "plt.legend(fontsize='x-small')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5f04757",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = dPdt_averaged/kI #Finding I \n",
    "I_std = I * np.sqrt((dPdt_std/dPdt_averaged)**2 + (kI_SD/kI)**2) #Doing error propagation on I\n",
    "\n",
    "'''\n",
    "#Remove commenting out for plotting\n",
    "#The part below is a visual check(plotting [I]t with error vs time)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(T_der, I, label=f'10 uM of subst.')\n",
    "plt.plot(T_der, I-I_std, alpha=0.3)\n",
    "plt.plot(T_der, I+I_std, alpha=0.3)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('[I]t (uM)')\n",
    "plt.title('[I]t Averaged vs T_der')\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize='x-small')\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "#The time corresponding to derivative is in the middle of time points; hence need to find Pt\n",
    "#that would correspond to the time at which the derivative was found\n",
    "\n",
    "#The errors here were computed the same way as for dPdt\n",
    "P_mid_rep1 = (Pt_rep1[:,n:] + Pt_rep1[:,:-n])/2\n",
    "P_mid_rep2 = (Pt_rep2[:,n:] + Pt_rep2[:,:-n])/2 \n",
    "\n",
    "std_P_mid_rep1 = np.std(P_mid_rep1, axis=0)\n",
    "std_P_mid_rep2 = np.std(P_mid_rep2, axis=0)\n",
    "\n",
    "P_mid_std = np.sqrt((std_P_mid_rep1**2 + std_P_mid_rep2**2)/4)\n",
    "P_mid = np.concatenate((P_mid_rep1,P_mid_rep2),axis=0)\n",
    "\n",
    "P_mid_averaged = np.mean(P_mid,axis=0)\n",
    "\n",
    "I_plus_P = I + P_mid_averaged\n",
    "I_plus_P_std = np.sqrt((I_std)**2+(P_mid_std)**2)\n",
    "\n",
    "'''\n",
    "#Remove commenting out for plotting\n",
    "#The part below is a visual check(plotting [I]t+[P]t with error vs time)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(T_der, I_plus_P, label=f'10 uM of subst.')\n",
    "plt.plot(T_der, I_plus_P-I_plus_P_std, alpha=0.3)\n",
    "plt.plot(T_der, I_plus_P+I_plus_P_std, alpha=0.3)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('[I]t + [P]t (uM)')\n",
    "plt.title('[I]t+[P]t_Averaged vs T_der')\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize='x-small')\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "#Remove commenting out for plotting\n",
    "#The part below is a visual check(plotting [I]t+[P]t with error vs time)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(T_der, I, label=f'[I]t')\n",
    "plt.plot(T_der, I-I_std, alpha=0.3)\n",
    "plt.plot(T_der, I+I_std, alpha=0.3)\n",
    "plt.plot(T_der, I_plus_P, label=f'[I]t+[P]t')\n",
    "plt.plot(T_der, I_plus_P-I_plus_P_std, alpha=0.3)\n",
    "plt.plot(T_der, I_plus_P+I_plus_P_std, alpha=0.3)\n",
    "plt.plot(T,Pt_averaged,'k-',linewidth=2.5, label=f'[P]t')\n",
    "plt.plot(T,Pt_averaged+Pt_std,'k--',linewidth=1,alpha=0.3)\n",
    "plt.plot(T,Pt_averaged-Pt_std,'k--',linewidth=1,alpha=0.3)\n",
    "plt.plot(T[window],func(T[window],Pinf,Itmin,kI),'r--',linewidth=3, label='Exponential fit')\n",
    "plt.legend(fontsize='x-small')\n",
    "plt.axvline(x=tmin,linestyle='-',color='black',alpha=0.3,label='_nolegend_')\n",
    "plt.axvline(x=tmax,linestyle='-',color='black',alpha=0.3,label='_nolegend_')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Concentration (uM)')\n",
    "plt.title('[I]t,[P]t, and [I]t+[P]t vs Time')\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize='x-small')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe770c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting Pt_averaged and fitted Pt along with corresopnding SD and time into Excel for plotting \n",
    "Pt_averaged_df = pandas.DataFrame(Pt_averaged)\n",
    "Pt_std_df = pandas.DataFrame(Pt_std)\n",
    "T_df = pandas.DataFrame(T)\n",
    "T_window_df = pandas.DataFrame(T[window])\n",
    "Pt_fitted_df = pandas.DataFrame(func(T[window],Pinf,Itmin,kI))\n",
    "\n",
    "with pandas.ExcelWriter('OUTPUT_ki_Opt-3_Product_Conc_Averaged_and_Fitted_Product_Progress_Curves.xlsx', engine='openpyxl') as writer:\n",
    "    \n",
    "    Pt_averaged_df.to_excel(writer, sheet_name='Pt_av')\n",
    "    Pt_std_df.to_excel(writer, sheet_name='Pt_std')\n",
    "    T_df.to_excel(writer, sheet_name='T')\n",
    "    T_window_df.to_excel(writer, sheet_name='T_window')\n",
    "    Pt_fitted_df.to_excel(writer, sheet_name='Pt_fitted')\n",
    "    \n",
    "    \n",
    "#Exporting I and I_plus_P along with corresopnding SD and time into Excel for plotting \n",
    "I_df = pandas.DataFrame(I)\n",
    "I_std_df = pandas.DataFrame(I_std)\n",
    "I_plus_P_df = pandas.DataFrame(I_plus_P)\n",
    "I_plus_P_std_df = pandas.DataFrame(I_plus_P_std)\n",
    "T_der_df = pandas.DataFrame(T_der)\n",
    "\n",
    "with pandas.ExcelWriter('OUTPUT_ki_Opt-3_I_and_I_plus_P_Progress_Curves.xlsx', engine='openpyxl') as writer:\n",
    "  \n",
    "    I_df.to_excel(writer, sheet_name='I')\n",
    "    I_std_df.to_excel(writer, sheet_name='I_std')\n",
    "    I_plus_P_df.to_excel(writer, sheet_name='I_plus_P')\n",
    "    I_plus_P_std_df.to_excel(writer, sheet_name='I_plus_P_std')\n",
    "    T_der_df.to_excel(writer, sheet_name='T_der')\n",
    "    \n",
    "#Exporting ki, half-life, P_inf, I_tmin + their corresponding error (SD or 95% confidence interval)\n",
    "\n",
    "# Open a text file in write mode\n",
    "with open('OUTPUT_kI_Experiment_All_Parameters_And_Error.txt', 'w') as f:\n",
    "    # Redirect print statements to the file   \n",
    "    print(\"fitted k_I [1/s] =\", kI, file=f)\n",
    "    print(\"fitted half-life [min] =\", t_half, file=f)\n",
    "    print(\"fitted P_inf [uM] =\", Pinf, file=f)\n",
    "    print(\"fitted I_tmin [uM] =\", Itmin, file=f)\n",
    "    print(\"95% confidence interval on fitted k_I [1/s] =\", kI_95_conf_int, file=f)\n",
    "    print(\"STD on fitted k_I [1/s] =\", kI_SD, file=f)\n",
    "    print(\"95% confidence interval on fitted P_inf[uM] =\", Pinf_95_conf_int, file=f)\n",
    "    print(\"95% confidence interval on fitted half-life [min] =\", t_half_95_conf_int, file=f)\n",
    "    print(\"95% confidence interval on fitted I_tmin [uM] =\", Itmin_conf_int, file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
